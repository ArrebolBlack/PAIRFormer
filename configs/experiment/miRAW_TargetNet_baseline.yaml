# @package _global_


# miRAW_TargetNet_baseline.yaml
# 一份“单实验”的完整配置，可以直接作为 config_name 使用
# 或者放在 configs/experiment/ 里当 baseline 模板。

# configs/experiment/miRAW_TargetNet_baseline.yaml
# 关键：把这个 experiment 的内容 merge 到根节点
# 而不是挂在 cfg.experiment 下面


# ---- 顶层元信息（推荐有） ----
experiment_name: "miRAW_TargetNet_baseline"  # 实验名，用于 WandB / 日志前缀
experiment:
  name: miRAW_TargetNet_baseline
  task: window_level_train    

seed: 2020                                   # 全局随机种子 
device: "cuda"                               # "cuda" / "cpu"

# ============================================================
# 1. 数据配置 data
# ============================================================
data:
  # 数据集名字（纯标识，用于日志）
  name: mirna_miraw

  # 原始 txt 路径（相对于项目根目录）
  path:
    train: "data/miRAW_Train_Validation.txt"
    val:   "data/miRAW_Train_Validation.txt"
    test:  "data/miRAW_Test0.txt"

  # 是否包含 ESA 特征（保持与你现有 DataConfig 逻辑一致）
  with_esa: true

# ============================================================
# 2. 模型配置 model
# ============================================================
model:
  # 模型在实验中的名字（随便起，用于日志）
  name: targetnet_default

  # 模型架构标识：用于 registry 中选择具体实现
  arch: TargetNet

  # 以下为 TargetNet 的结构超参（可以按需改）
  num_channels:      [16, 16, 32]
  num_blocks:        [2, 1, 1]
  pool_size:         3
  stem_kernel_size:  5
  block_kernel_size: 3
  skip_connection:   true
  dropout:           0.5

# ============================================================
# 3. 训练配置 train（Trainer 用）
# ============================================================
train:
  # --- 优化器 & 学习率 ---
  optimizer: adam              # ["adamw", "adam", "sgd", "rmsprop"]
  lr: 0.001
  weight_decay: 0.01
  momentum: 0.9                # 仅对 SGD 有效

  # --- 学习率调度器 ---
  scheduler: plateau              # ["none", "plateau", "cosine", "step"]
  scheduler_factor: 0.2        # for ReduceLROnPlateau
  scheduler_patience: 5
  scheduler_t_max: 10          # for CosineAnnealingLR
  scheduler_step_size: 10      # for StepLR
  scheduler_gamma: 0.1

  # --- 损失 & 数值稳定 ---
  loss_type: bce               # "bce" or "mse" or "custom"
  amp: true                    # 是否使用混合精度
  grad_clip: 1.0               # None 或 float

  # --- EMA（可选） ---
  ema:
    enabled: false
    decay: 0.999

  # --- 监控指标（决定 best.pt 保存逻辑） ---
  monitor: loss                # "loss" / "f1" / "roc_auc" / ...
  greater_is_better: false     # 对 loss 应设为 false，对 F1/AUC 设为 true

# ============================================================
# 4. 任务配置 task（metrics / evaluator 用）
# ============================================================
task:
  # 问题类型：影响损失与 metrics 行为
  problem_type: binary_classification   # or "regression"

  # y_pred_raw 是否为 logits，需要内部做 sigmoid
  from_logits: true

  # 最简单版本：固定阈值
  # （之后可以扩展为 threshold.fixed / sweep 等更复杂结构）
  threshold: 0.5

# ============================================================
# 5. 运行配置 run（train.py / eval.py 通用）
# ============================================================
run:
  # 当前运行模式（主要语义标记）
  mode: train                       # "train" / "eval"

  # 训练轮数
  num_epochs: 50

  # DataLoader 超参数（train & eval 共用）
  batch_size: 256
  num_workers: 4
  pin_memory: true

  # 数据缓存路径（通常相对于项目根目录）
  cache_path: "${paths.cache_root}"

  # checkpoint / resume 策略
  resume: false                     # train: 是否尝试从 checkpoint 恢复
  checkpoint: null                  # train 默认 None；eval 模式下必须显式指定

  # 输出子目录（相对于 hydra.run.dir）
  ckpt_subdir: "checkpoints"
  eval_subdir: "eval"
  
  eval_test_after_train: true
  test_splits: ["test"]

# ============================================================
# 6. 评估配置 eval（evaluator 使用）
# ============================================================
eval:
  # 顶层输出目录名（一般不用改，实际路径= run.eval_subdir / split_idx）
  save_dir: "eval_outputs"

  # 是否在当前 split 上扫阈值（训练结束的 val eval 就会用到）
  do_threshold_sweep: true
  sweep_num_thresholds: 101    # 扫描 0~1 上的阈值个数

  # 是否从 val 阶段的 best_threshold.json 读阈值（主要给 test eval 用）
  use_val_best_threshold: false
  best_threshold_path: null    # 为空时默认尝试 eval/val/best_threshold.json

  # 输出内容控制
  save_metrics_json: true
  save_report_txt: true
  save_threshold_csv: true
  save_curves_png: true

  # 曲线文件名（放在对应 split 目录下）
  roc_curve_file: "roc_curve.png"
  pr_curve_file: "pr_curve.png"

# ============================================================
# 7. 日志 & WandB 配置 logging
# ============================================================
logging:
  # 训练 & eval 统一使用的 WandB 基本设置
  wandb:
    enabled: true                  # 打开后 train/eval 都会 init wandb
    project: "TargetNet"
    entity: null
    mode: "online"                  # "online" / "offline" / "disabled"
    group: miRAW_baseline
    tags: ["TargetNet"]

  # evaluator 内部使用的前缀设置（写 summary 时可以加上 eval/）
  eval:
    use_wandb: false                # 是否在 evaluator 中额外写 wandb summary
    wandb_prefix: "eval"

# ============================================================
# 8. 路径命名空间 paths（统一收口）
# ============================================================
paths:
  # 所有实验输出的根目录（通常配合 Hydra 的 hydra.run.dir 一起用）
  output_root: "outputs"

  # 数据 cache 根目录
  cache_root: "cache"

  # 日志根目录（给以后 logger / 自定义文件日志预留）
  logs_root: "logs"
